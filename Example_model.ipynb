{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Example_model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohith616/Client-Project-1/blob/main/Example_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install common evalml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uEIrHphIafmY",
        "outputId": "4a97ec4f-6003-4e57-8ed6-3f01af5ad71c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting common\n",
            "  Downloading common-0.1.2.tar.gz (3.5 kB)\n",
            "Collecting evalml\n",
            "  Downloading evalml-0.43.0-py3-none-any.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipywidgets>=7.5 in /usr/local/lib/python3.7/dist-packages (from evalml) (7.6.5)\n",
            "Collecting featuretools>=1.2.0\n",
            "  Downloading featuretools-1.6.0-py3-none-any.whl (356 kB)\n",
            "\u001b[K     |████████████████████████████████| 356 kB 41.2 MB/s \n",
            "\u001b[?25hCollecting scipy>=1.5.0\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.7 MB/s \n",
            "\u001b[?25hCollecting sktime>=0.7.0\n",
            "  Downloading sktime-0.10.1-py3-none-any.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 24.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas<1.4.0,>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from evalml) (1.3.5)\n",
            "Collecting colorama>=0.4.4\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from evalml) (7.1.2)\n",
            "Collecting statsmodels>=0.12.2\n",
            "  Downloading statsmodels-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8 MB 10.6 MB/s \n",
            "\u001b[?25hCollecting vowpalwabbit>=8.11.0\n",
            "  Downloading vowpalwabbit-9.0.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 27.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from evalml) (1.0.2)\n",
            "Collecting kaleido>=0.1.0\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 79.9 MB 79 kB/s \n",
            "\u001b[?25hCollecting pmdarima>=1.8.1\n",
            "  Downloading pmdarima-1.8.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 32.7 MB/s \n",
            "\u001b[?25hCollecting woodwork>=0.11.0\n",
            "  Downloading woodwork-0.13.0-py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 40.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from evalml) (0.11.2)\n",
            "Collecting matplotlib>=3.3.3\n",
            "  Downloading matplotlib-3.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 28.3 MB/s \n",
            "\u001b[?25hCollecting scikit-optimize>=0.8.1\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 8.5 MB/s \n",
            "\u001b[?25hCollecting xgboost>=1.4.2\n",
            "  Downloading xgboost-1.5.2-py3-none-manylinux2014_x86_64.whl (173.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 173.6 MB 8.1 kB/s \n",
            "\u001b[?25hCollecting requirements-parser>=0.2.0\n",
            "  Downloading requirements_parser-0.5.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: imbalanced-learn>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from evalml) (0.8.1)\n",
            "Collecting lightgbm>=2.3.1\n",
            "  Downloading lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 44.2 MB/s \n",
            "\u001b[?25hCollecting graphviz>=0.13\n",
            "  Downloading graphviz-0.19.1-py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyzmq>=20.0.0 in /usr/local/lib/python3.7/dist-packages (from evalml) (22.3.0)\n",
            "Collecting catboost>=0.20\n",
            "  Downloading catboost-1.0.4-cp37-none-manylinux1_x86_64.whl (76.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.1 MB 53 kB/s \n",
            "\u001b[?25hCollecting shap>=0.36.0\n",
            "  Downloading shap-0.40.0-cp37-cp37m-manylinux2010_x86_64.whl (564 kB)\n",
            "\u001b[K     |████████████████████████████████| 564 kB 39.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from evalml) (1.21.5)\n",
            "Collecting lime>=0.2.0.1\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[K     |████████████████████████████████| 275 kB 49.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from evalml) (5.5.0)\n",
            "Collecting cloudpickle>=1.5.0\n",
            "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
            "Collecting networkx<2.6,>=2.5\n",
            "  Downloading networkx-2.5.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 40.8 MB/s \n",
            "\u001b[?25hCollecting texttable>=1.6.2\n",
            "  Downloading texttable-1.6.4-py2.py3-none-any.whl (10 kB)\n",
            "Collecting nlp-primitives>=2.1.0\n",
            "  Downloading nlp_primitives-2.2.0-py3-none-any.whl (44.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 44.7 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting dask>=2021.10.0\n",
            "  Downloading dask-2022.2.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 39.8 MB/s \n",
            "\u001b[?25hCollecting category-encoders>=2.2.2\n",
            "  Downloading category_encoders-2.3.0-py2.py3-none-any.whl (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 328 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost>=0.20->evalml) (1.15.0)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category-encoders>=2.2.2->evalml) (0.5.2)\n",
            "Collecting fsspec>=0.6.0\n",
            "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 49.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from dask>=2021.10.0->evalml) (21.3)\n",
            "Collecting partd>=0.3.10\n",
            "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting pyyaml>=5.3.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 51.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask>=2021.10.0->evalml) (0.11.2)\n",
            "Collecting psutil>=5.6.6\n",
            "  Downloading psutil-5.9.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 59.5 MB/s \n",
            "\u001b[?25hCollecting holidays>=0.13\n",
            "  Downloading holidays-0.13-py3-none-any.whl (172 kB)\n",
            "\u001b[K     |████████████████████████████████| 172 kB 58.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.32.0 in /usr/local/lib/python3.7/dist-packages (from featuretools>=1.2.0->evalml) (4.62.3)\n",
            "Collecting distributed>=2021.10.0\n",
            "  Downloading distributed-2022.2.0-py3-none-any.whl (837 kB)\n",
            "\u001b[K     |████████████████████████████████| 837 kB 72.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.10.0->featuretools>=1.2.0->evalml) (2.0.0)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.10.0->featuretools>=1.2.0->evalml) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.10.0->featuretools>=1.2.0->evalml) (1.7.0)\n",
            "Requirement already satisfied: tornado>=5 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.10.0->featuretools>=1.2.0->evalml) (5.1.1)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.10.0->featuretools>=1.2.0->evalml) (1.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.10.0->featuretools>=1.2.0->evalml) (57.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.10.0->featuretools>=1.2.0->evalml) (2.11.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from holidays>=0.13->featuretools>=1.2.0->evalml) (2.8.2)\n",
            "Requirement already satisfied: convertdate>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from holidays>=0.13->featuretools>=1.2.0->evalml) (2.4.0)\n",
            "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.7/dist-packages (from holidays>=0.13->featuretools>=1.2.0->evalml) (0.2.1)\n",
            "Requirement already satisfied: hijri-converter in /usr/local/lib/python3.7/dist-packages (from holidays>=0.13->featuretools>=1.2.0->evalml) (2.2.2)\n",
            "Requirement already satisfied: pymeeus<=1,>=0.3.13 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.3.0->holidays>=0.13->featuretools>=1.2.0->evalml) (0.5.11)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn>=0.8.0->evalml) (1.1.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->evalml) (5.1.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->evalml) (1.0.2)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->evalml) (5.1.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->evalml) (3.5.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->evalml) (0.2.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->evalml) (5.5.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->evalml) (4.10.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->evalml) (5.3.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->evalml) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->evalml) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->evalml) (1.0.18)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->evalml) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->evalml) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->evalml) (2.6.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.3.1->evalml) (0.37.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.7/dist-packages (from lime>=0.2.0.1->evalml) (0.18.3)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.29.1-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 55.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.3->evalml) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.3->evalml) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.3->evalml) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.3->evalml) (1.3.2)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5->evalml) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5->evalml) (4.9.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5->evalml) (0.18.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5->evalml) (4.11.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5->evalml) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5->evalml) (3.10.0.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5->evalml) (21.4.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5->evalml) (3.7.0)\n",
            "Collecting nltk>=3.4.5\n",
            "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 28.2 MB/s \n",
            "\u001b[?25hCollecting regex>=2021.8.3\n",
            "  Downloading regex-2022.1.18-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (748 kB)\n",
            "\u001b[K     |████████████████████████████████| 748 kB 40.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<1.4.0,>=1.3.0->evalml) (2018.9)\n",
            "Collecting locket\n",
            "  Downloading locket-0.2.1-py2.py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly>=5.0.0->evalml) (8.0.1)\n",
            "Requirement already satisfied: Cython!=0.29.18,>=0.29 in /usr/local/lib/python3.7/dist-packages (from pmdarima>=1.8.1->evalml) (0.29.27)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from pmdarima>=1.8.1->evalml) (1.24.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets>=7.5->evalml) (0.2.5)\n",
            "Collecting types-setuptools>=57.0.0\n",
            "  Downloading types_setuptools-57.4.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime>=0.2.0.1->evalml) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime>=0.2.0.1->evalml) (1.2.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime>=0.2.0.1->evalml) (2.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->evalml) (3.1.0)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap>=0.36.0->evalml) (0.51.2)\n",
            "Collecting deprecated>=1.2.13\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting numba\n",
            "  Downloading numba-0.55.1-1-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 23.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.13->sktime>=0.7.0->evalml) (1.13.3)\n",
            "Collecting llvmlite<0.39,>=0.38.0rc1\n",
            "  Downloading llvmlite-0.38.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.5 MB 4.9 kB/s \n",
            "\u001b[?25hRequirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (5.3.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (1.8.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (0.13.1)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (0.7.0)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2021.10.0->featuretools>=1.2.0->evalml) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->distributed>=2021.10.0->featuretools>=1.2.0->evalml) (2.0.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (1.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (0.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (0.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (4.1.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (0.8.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (0.5.1)\n",
            "Building wheels for collected packages: common, lime\n",
            "  Building wheel for common (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for common: filename=common-0.1.2-py3-none-any.whl size=3732 sha256=2395b14133467f36a9636f07608bd048060d2118900675ece621a8bbe50866c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/88/ea/416ddc295a285f3661c88772a64b4a3766a92ce55f7b01dd9d\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283857 sha256=84448aeeda7adb6eb8aedf09b947431dc437f37473c1a1c63ec48f4151032c89\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/cb/e5/ac701e12d365a08917bf4c6171c0961bc880a8181359c66aa7\n",
            "Successfully built common lime\n",
            "Installing collected packages: locket, scipy, pyyaml, partd, fsspec, cloudpickle, psutil, fonttools, dask, woodwork, regex, networkx, matplotlib, llvmlite, holidays, distributed, types-setuptools, statsmodels, slicer, pyaml, numba, nltk, graphviz, featuretools, deprecated, xgboost, vowpalwabbit, texttable, sktime, shap, scikit-optimize, requirements-parser, pmdarima, nlp-primitives, lime, lightgbm, kaleido, colorama, category-encoders, catboost, evalml, common\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2.12.0\n",
            "    Uninstalling dask-2.12.0:\n",
            "      Successfully uninstalled dask-2.12.0\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 2.6.3\n",
            "    Uninstalling networkx-2.6.3:\n",
            "      Successfully uninstalled networkx-2.6.3\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: holidays\n",
            "    Found existing installation: holidays 0.10.5.2\n",
            "    Uninstalling holidays-0.10.5.2:\n",
            "      Successfully uninstalled holidays-0.10.5.2\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "  Attempting uninstall: statsmodels\n",
            "    Found existing installation: statsmodels 0.10.2\n",
            "    Uninstalling statsmodels-0.10.2:\n",
            "      Successfully uninstalled statsmodels-0.10.2\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed catboost-1.0.4 category-encoders-2.3.0 cloudpickle-2.0.0 colorama-0.4.4 common-0.1.2 dask-2022.2.0 deprecated-1.2.13 distributed-2022.2.0 evalml-0.43.0 featuretools-1.6.0 fonttools-4.29.1 fsspec-2022.1.0 graphviz-0.19.1 holidays-0.13 kaleido-0.2.1 lightgbm-3.3.2 lime-0.2.0.1 llvmlite-0.38.0 locket-0.2.1 matplotlib-3.5.1 networkx-2.5.1 nlp-primitives-2.2.0 nltk-3.7 numba-0.55.1 partd-1.2.0 pmdarima-1.8.4 psutil-5.9.0 pyaml-21.10.1 pyyaml-6.0 regex-2022.1.18 requirements-parser-0.5.0 scikit-optimize-0.9.0 scipy-1.7.3 shap-0.40.0 sktime-0.10.1 slicer-0.0.7 statsmodels-0.13.2 texttable-1.6.4 types-setuptools-57.4.9 vowpalwabbit-9.0.1 woodwork-0.13.0 xgboost-1.5.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cloudpickle",
                  "matplotlib",
                  "mpl_toolkits",
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWXV7zoY6cIm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from fbprophet import Prophet\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "\n",
        "from . import common\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    data: pd.DataFrame, future_data: pd.DataFrame, parameters: dict\n",
        ") -> [Prophet, pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    1. データをモデルの形に合うように整形\n",
        "    2. モデルによる学習\n",
        "    3. 検証用予測データと未来の予測データを作成\n",
        "\n",
        "    Args:\n",
        "        data (pandas.DataFrame): 学習データ\n",
        "        future_data (pandas.DataFrame): 予測用の未来データ\n",
        "        validation_data_ratio (float): 学習データから取得する検証データ比率\n",
        "\n",
        "    Returns:\n",
        "        Prophet: 学習済みモデルオブジェクト\n",
        "        pd.DataFrame: 検証用予測データ\n",
        "        pd.DataFrame: 未来の予測データ\n",
        "    \"\"\"\n",
        "    process_name = re.split(\"[/_.]\", __file__)[-2]\n",
        "    common.print_process_start(process_name)\n",
        "\n",
        "    # 型変換\n",
        "    data[\"ds\"] = pd.to_datetime(data[\"ds\"])\n",
        "    data[\"target_id\"] = data[\"target_id\"].astype(str)\n",
        "    data[\"y\"] = data[\"y\"].astype(float)\n",
        "    future_data[\"ds\"] = pd.to_datetime(future_data[\"ds\"])\n",
        "    future_data[\"target_id\"] = future_data[\"target_id\"].astype(str)\n",
        "\n",
        "    # 有効なカラム取得\n",
        "    use_cols = data.dropna(axis=1, how=\"all\").columns\n",
        "\n",
        "    # 回帰変数(数値)\n",
        "    reg_numerics = [\n",
        "        k for k, v in data.dtypes.items() if v in [int, float] and k not in [\"y\"]\n",
        "    ]\n",
        "    # 回帰変数(カテゴリ)\n",
        "    reg_categories = [\n",
        "        k\n",
        "        for k, v in data.dtypes.items()\n",
        "        if v == object and k not in [\"target_id\", \"target_address\", \"holiday\"]\n",
        "    ]\n",
        "\n",
        "    def sub_func(data, future_data):\n",
        "        # モデルに組み込む回帰変数(後でダミー化カテゴリ変数を追加)\n",
        "        regressors = reg_numerics.copy()\n",
        "\n",
        "        # 休日データ組込\n",
        "        holidays = data.loc[~data[\"holiday\"].isna(), \"ds\"]\n",
        "        holidays = holidays.append(\n",
        "            future_data.loc[~future_data[\"holiday\"].isna(), \"ds\"]\n",
        "        )\n",
        "        holidays = pd.DataFrame(\n",
        "            {\"holiday\": \"holiday\", \"ds\": holidays, \"lower_window\": 0, \"upper_window\": 1}\n",
        "        )\n",
        "\n",
        "        # イベントデータ組込\n",
        "        if \"events\" in use_cols:\n",
        "            events = data.loc[~data[\"events\"].isna(), [\"ds\", \"events\"]]\n",
        "            events = events.append(\n",
        "                future_data.loc[~future_data[\"events\"].isna(), [\"ds\", \"events\"]]\n",
        "            )\n",
        "            events = pd.DataFrame(\n",
        "                {\n",
        "                    \"holiday\": \"events\",\n",
        "                    \"ds\": events[\"ds\"],\n",
        "                    \"lower_window\": 0,\n",
        "                    \"upper_window\": 1,\n",
        "                }\n",
        "            )\n",
        "            holidays = holidays.append(events)\n",
        "\n",
        "        # カテゴリ変数のダミー化\n",
        "        all_data = pd.get_dummies(data.append(future_data), columns=reg_categories)\n",
        "        data = all_data.iloc[: len(data)]\n",
        "        future_data = all_data.iloc[-len(future_data) :]\n",
        "        regressors.extend(\n",
        "            data.columns[\n",
        "                data.columns.str.contains(\"|\".join(reg_categories), regex=True)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # 学習／検証データ設定\n",
        "        tmp_train_data, validation_data = train_test_split(\n",
        "            data, test_size=parameters[\"common\"][\"validation_data_ratio\"], shuffle=False\n",
        "        )\n",
        "        if parameters[\"common\"][\"train_test_split\"]:  # 検証データを学習に使わない\n",
        "            train_data = tmp_train_data\n",
        "        else:  # 検証データ含めて学習する\n",
        "            train_data = data\n",
        "\n",
        "        # 学習\n",
        "        feed_dict = parameters[\"models_prophet\"]\n",
        "        feed_dict[\"holidays\"] = holidays\n",
        "        model = Prophet(**feed_dict)\n",
        "        for reg in regressors:\n",
        "            model.add_regressor(reg)\n",
        "        model.fit(train_data[[\"ds\", \"y\"] + regressors])\n",
        "\n",
        "        # 検証データの予測検証\n",
        "        validation_data = validation_data.reset_index(drop=True)\n",
        "        pred = model.predict(validation_data[[\"ds\"] + regressors])\n",
        "        pred = pred[[\"ds\", \"yhat\"]]\n",
        "        pred = pred.rename(columns={\"yhat\": \"y\"})\n",
        "\n",
        "        # 未来データの予測\n",
        "        future_pred = model.predict(future_data[[\"ds\"] + regressors])\n",
        "        future_pred = future_pred[[\"ds\", \"yhat\"]]\n",
        "        future_pred = future_pred.rename(columns={\"yhat\": \"y\"})\n",
        "\n",
        "        return model, pred[[\"ds\", \"y\"]], future_pred[[\"ds\", \"y\"]]\n",
        "\n",
        "    # 実行処理\n",
        "    results = {\"model\": {}, \"pred\": [], \"future_pred\": []}\n",
        "    for target_id, sub_data in data.groupby(\"target_id\"):\n",
        "        sub_future_data = future_data[future_data[\"target_id\"] == target_id]\n",
        "        model, pred, future_pred = sub_func(sub_data, sub_future_data)\n",
        "        results[\"model\"][target_id] = model\n",
        "        results[\"pred\"].append(pred.assign(target_id=target_id))\n",
        "        results[\"future_pred\"].append(future_pred.assign(target_id=target_id))\n",
        "    model = results[\"model\"]\n",
        "    pred = pd.concat(results[\"pred\"], axis=0)\n",
        "    future_pred = pd.concat(results[\"future_pred\"], axis=0)\n",
        "\n",
        "    common.print_process_end(process_name)\n",
        "\n",
        "    return [\n",
        "        model,\n",
        "        pred[[\"ds\", \"target_id\", \"y\"]],\n",
        "        future_pred[[\"ds\", \"target_id\", \"y\"]],\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.algorithms import rank\n",
        "if __name__ == \"__main__\":\n",
        "    data = pd.read_csv(\"/content/drive/MyDrive/Datasets/preprocessed_data.csv\")\n",
        "    future_data = data.drop(\"y\", axis=1)\n",
        "    future_data = future_data.iloc[:1000]\n",
        "    parameters = {\n",
        "        \"model_evalML\": {\n",
        "            \"gap\": 0,\n",
        "            \"max_delay\": 7,\n",
        "            \"forecast_horizon\": 7,\n",
        "            \"time_index\": \"ds\",\n",
        "        }\n",
        "    }\n",
        "    automl = train_model(data, future_data, parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "id": "8sHJj8qF1JYv",
        "outputId": "d47f77cb-bffb-4f1a-ef69-1e84f42101e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Time series support in evalml is still in beta, which means we are still actively building its core features. Please be mindful of that when running search().\n",
            "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.766e+04, tolerance: 4.867e+00\n",
            "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.725e+04, tolerance: 1.009e+01\n",
            "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.985e+04, tolerance: 1.540e+01\n",
            "stepwise model cannot be fit in parallel (n_jobs=1). Falling back to stepwise parameter search.\n",
            "Error fitting  ARIMA(2,0,2)(0,0,0)[0] intercept (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
            "Error fitting  ARIMA(0,0,0)(0,0,0)[0] intercept (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
            "Error fitting  ARIMA(1,0,0)(0,0,0)[0] intercept (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
            "Error fitting  ARIMA(0,0,1)(0,0,0)[0] intercept (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
            "Error fitting  ARIMA(1,0,1)(0,0,0)[0] intercept (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
            "stepwise model cannot be fit in parallel (n_jobs=1). Falling back to stepwise parameter search.\n",
            "Error fitting  ARIMA(2,0,2)(0,0,0)[0] intercept (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
            "Error fitting  ARIMA(0,0,0)(0,0,0)[0] intercept (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
            "Error fitting  ARIMA(1,0,0)(0,0,0)[0] intercept (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
            "Error fitting  ARIMA(0,0,1)(0,0,0)[0] intercept (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
            "Error fitting  ARIMA(1,0,1)(0,0,0)[0] intercept (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
            "stepwise model cannot be fit in parallel (n_jobs=1). Falling back to stepwise parameter search.\n",
            "Error fitting  ARIMA(2,0,2)(0,0,0)[0] intercept (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
            "Error fitting  ARIMA(0,0,0)(0,0,0)[0] intercept (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
            "Error fitting  ARIMA(1,0,0)(0,0,0)[0] intercept (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
            "Error fitting  ARIMA(0,0,1)(0,0,0)[0] intercept (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
            "Error fitting  ARIMA(1,0,1)(0,0,0)[0] intercept (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
            "stepwise model cannot be fit in parallel (n_jobs=1). Falling back to stepwise parameter search.\n",
            "Error fitting  ARIMA(2,0,2)(0,0,0)[0] intercept (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
            "Error fitting  ARIMA(0,0,0)(0,0,0)[0] intercept (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
            "Error fitting  ARIMA(1,0,0)(0,0,0)[0] intercept (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
            "Error fitting  ARIMA(0,0,1)(0,0,0)[0] intercept (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
            "Error fitting  ARIMA(1,0,1)(0,0,0)[0] intercept (if you do not want to see these warnings, run with error_action=\"ignore\").\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-31b9a5f897b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         }\n\u001b[1;32m     13\u001b[0m     }\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mautoml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-8fc72884d18b>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(data, future_data, parameters)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtarget_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"target_id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0msub_future_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfuture_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msub_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_future_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pred\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-8fc72884d18b>\u001b[0m in \u001b[0;36msub_func\u001b[0;34m(data, future_data)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         )\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ds\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"yhat\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"yhat\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    964\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0;31m# handle the dup indexing case GH#4246\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_values_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1151\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1095\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1372\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['ds', 'yhat'], dtype='object')] are in the [index]\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAY-5q8weG0O",
        "outputId": "ed3f5e12-3b78-4bd3-c8fd-a8e56241d2bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for the example pipeline. Feel free to delete these once you\n",
        "# remove the example pipeline from hooks.py and the example nodes in\n",
        "# `src/pipelines/`\n",
        "# Documentation for this file format can be found in \"Parameters\"\n",
        "# Link: https://kedro.readthedocs.io/en/stable/04_kedro_project_setup/02_configuration.html#parameters\n",
        "\n",
        "# common\n",
        "common:\n",
        "  validation_data_ratio: 0.2\n",
        "  train_test_split: True\n",
        "\n",
        "# data collection\n",
        "collection_holiday: null\n",
        "collection_weather: null\n",
        "\n",
        "# data typing\n",
        "data_typing: \n",
        "  data_types: {}\n",
        "  data_properties:\n",
        "    Meta: \n",
        "      - target_id\n",
        "      - target_address\n",
        "    DateTime: []\n",
        "    Numeric: []\n",
        "    Category: []\n",
        "\n",
        "# data preparation\n",
        "data_preparation:\n",
        "  freq_day: 1\n",
        "\n",
        "# data preprocessing\n",
        "data_preprocessing:\n",
        "  interpolate:\n",
        "    methods: {}\n",
        "  transform:\n",
        "    methods: {}\n",
        "\n",
        "# feature engineering\n",
        "feature_engineering: null\n",
        "\n",
        "# prophet\n",
        "models_prophet:\n",
        "  growth: 'linear'\n",
        "  changepoints: null\n",
        "  n_changepoints: 25\n",
        "  changepoint_range: 0.8\n",
        "  yearly_seasonality: 'auto'\n",
        "  weekly_seasonality: 'auto'\n",
        "  daily_seasonality: 'auto'\n",
        "  seasonality_mode: 'additive'\n",
        "  seasonality_prior_scale: 10.0\n",
        "  holidays_prior_scale: 10.0\n",
        "  changepoint_prior_scale: 0.05\n",
        "  interval_width: 0.8\n",
        "\n",
        "# sktime_AutoARIMA\n",
        "models_sktime_AutoARIMA:\n",
        "  start_p: 2\n",
        "  d: null\n",
        "  start_q: 2\n",
        "  max_p: 5\n",
        "  max_d: 2\n",
        "  max_q: 5\n",
        "  start_P: 1\n",
        "  D: null\n",
        "  start_Q: 1\n",
        "  max_P: 2\n",
        "  max_D: 1\n",
        "  max_Q: 2\n",
        "  max_order: 5\n",
        "  sp: 1\n",
        "  seasonal: False\n",
        "  # simple_differencing: True ※高速化するっぽいけどなお遅かったので切る\n",
        "\n",
        "# sktime_AutoETS\n",
        "models_sktime_AutoETS:\n",
        "  auto: True\n",
        "  sp: 1\n",
        "\n",
        "# sktime_ThetaForecaster\n",
        "models_sktime_ThetaForecaster:\n",
        "  sp: 1\n",
        "\n",
        "# evaluations\n",
        "evaluation_prophet: null\n",
        "evaluation_sktime_AutoARIMA: null\n",
        "evaluation_sktime_AutoETS: null\n",
        "evaluation_sktime_ThetaForecaster: null"
      ],
      "metadata": {
        "id": "0zeeg-ugaT_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "pandas.__version__ "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_OLd6Frc1LJy",
        "outputId": "f74a5c3f-e83d-4b7c-f283-1a11ad87b2b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.3.5'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lAA72781RXV",
        "outputId": "dbfaf83b-612f-4bfe-cb52-464fc57179b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ]
        }
      ]
    }
  ]
}